






deep q network



 - smooth l1 loss стабильнее mse loss при больших по модулю значениях Q ф-ции

 - приоритизация опыта - больше обучаемся на том опыте, на котором больше ошибаемся **(dqn per)**

 - dueling dqn
вводим advantage function

 - distributional dqn
идея - будем приближать не мат ожидание, а сразу само распределение Q ф-ции


- n step replay
- double dqn
- layer noise











